{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d7e3813-40cb-4f96-b505-16699fd6b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6322640-8197-4985-83cb-db0f6328058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch containers\n",
    "def fetchContainers():\n",
    "    password=input('please input your unix root password:')\n",
    "    cmd_containers='echo password|sudo -S ls -lrt /var/lib/docker/containers'\n",
    "    cmd_docker_log='docker logs '\n",
    "    result=np.array(subprocess.getoutput(cmd_containers).split('\\n'))[1:]\n",
    "    containers=[line.split(' ')[8] for line in result]\n",
    "    return containers\n",
    "    \n",
    "#print(containers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c665b843-eea4-4f2f-9873-a8bcf2bb5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_logs():\n",
    "    containers=fetchContainers()\n",
    "    total=len(containers)\n",
    "    i=0\n",
    "    while i<total-1:\n",
    "        container=containers[i]\n",
    "        print(subprocess.getoutput(f'docker logs {container}'))\n",
    "        user_input = input('please press u to previous or d for next log or x to quit:')\n",
    "        i={'u': (i-1), 'd': (i+1) }.get(user_input, total*10) \n",
    "        if i<0 :\n",
    "            i=total-1\n",
    "        if i==total:\n",
    "            i=0\n",
    "    print('Awesome!')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "649be48d-aef7-45e5-ad2f-707f1fb8843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please input your unix root password: password\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No such container: e0cd64f83a3cab2373634e7c819d3e26a61ea414f9e3dd2afa77485e0e47f4e3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please press u to previous or d for next log or x to quit: d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:C 12 Oct 2021 01:42:32.089 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n",
      "21:C 12 Oct 2021 01:42:32.089 # Redis version=6.2.2, bits=64, commit=00000000, modified=0, pid=21, just started\n",
      "21:C 12 Oct 2021 01:42:32.089 # Configuration loaded\n",
      "21:M 12 Oct 2021 01:42:32.089 * monotonic clock: POSIX clock_gettime\n",
      "                _._                                                  \n",
      "           _.-``__ ''-._                                             \n",
      "      _.-``    `.  `_.  ''-._           Redis 6.2.2 (00000000/0) 64 bit\n",
      "  .-`` .-```.  ```\\/    _.,_ ''-._                                  \n",
      " (    '      ,       .-`  | `,    )     Running in standalone mode\n",
      " |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n",
      " |    `-._   `._    /     _.-'    |     PID: 21\n",
      "  `-._    `-._  `-./  _.-'    _.-'                                   \n",
      " |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n",
      " |    `-._`-._        _.-'_.-'    |           https://redis.io       \n",
      "  `-._    `-._`-.__.-'_.-'    _.-'                                   \n",
      " |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n",
      " |    `-._`-._        _.-'_.-'    |                                  \n",
      "  `-._    `-._`-.__.-'_.-'    _.-'                                   \n",
      "      `-._    `-.__.-'    _.-'                                       \n",
      "          `-._        _.-'                                           \n",
      "              `-.__.-'                                               \n",
      "\n",
      "21:M 12 Oct 2021 01:42:32.090 # Server initialized\n",
      "21:M 12 Oct 2021 01:42:32.090 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n",
      "21:M 12 Oct 2021 01:42:32.090 * Ready to accept connections\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2021-10-12 01:42:33,341 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "2021-10-12 01:42:33,526 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\n",
      "Training Env:\n",
      "\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator\": \"RLEstimator\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1-7mq0q\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1-7mq0q\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"s3_bucket\": \"bucket\",\n",
      "        \"s3_prefix\": \"rl-deepracer-1\",\n",
      "        \"aws_region\": \"us-east-1\",\n",
      "        \"model_metadata_s3_key\": \"s3://bucket/custom_files/model_metadata.json\",\n",
      "        \"RLCOACH_PRESET\": \"deepracer\",\n",
      "        \"pretrained_s3_bucket\": \"bucket\",\n",
      "        \"pretrained_s3_prefix\": \"rl-deepracer-sagemaker\",\n",
      "        \"pretrained_checkpoint\": \"last\",\n",
      "        \"batch_size\": 64,\n",
      "        \"beta_entropy\": 0.01,\n",
      "        \"discount_factor\": 0.995,\n",
      "        \"e_greedy_value\": 0.05,\n",
      "        \"epsilon_steps\": 6000,\n",
      "        \"exploration_type\": \"categorical\",\n",
      "        \"loss_type\": \"huber\",\n",
      "        \"lr\": 3e-05,\n",
      "        \"num_episodes_between_training\": 36,\n",
      "        \"num_epochs\": 10,\n",
      "        \"stack_size\": 1,\n",
      "        \"term_cond_avg_score\": 100000.0,\n",
      "        \"term_cond_max_episodes\": 999999,\n",
      "        \"sac_alpha\": 0.2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rl-deepracer-1\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1-7mq0q\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://bucket/rl-deepracer-1/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"training_worker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 12,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1-7mq0q\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1-7mq0q\"\n",
      "        ]\n",
      "    },\n",
      "    \"user_entry_point\": \"training_worker.py\"\n",
      "}\n",
      "\n",
      "Environment variables:\n",
      "\n",
      "SM_HOSTS=[\"algo-1-7mq0q\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"RLCOACH_PRESET\":\"deepracer\",\"aws_region\":\"us-east-1\",\"batch_size\":64,\"beta_entropy\":0.01,\"discount_factor\":0.995,\"e_greedy_value\":0.05,\"epsilon_steps\":6000,\"exploration_type\":\"categorical\",\"loss_type\":\"huber\",\"lr\":3e-05,\"model_metadata_s3_key\":\"s3://bucket/custom_files/model_metadata.json\",\"num_episodes_between_training\":36,\"num_epochs\":10,\"pretrained_checkpoint\":\"last\",\"pretrained_s3_bucket\":\"bucket\",\"pretrained_s3_prefix\":\"rl-deepracer-sagemaker\",\"s3_bucket\":\"bucket\",\"s3_prefix\":\"rl-deepracer-1\",\"sac_alpha\":0.2,\"stack_size\":1,\"term_cond_avg_score\":100000.0,\"term_cond_max_episodes\":999999}\n",
      "SM_USER_ENTRY_POINT=training_worker.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\n",
      "SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-7mq0q\",\"hosts\":[\"algo-1-7mq0q\"]}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1-7mq0q\n",
      "SM_MODULE_NAME=training_worker\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=12\n",
      "SM_NUM_GPUS=1\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://bucket/rl-deepracer-1/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1-7mq0q\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-7mq0q\"],\"hyperparameters\":{\"RLCOACH_PRESET\":\"deepracer\",\"aws_region\":\"us-east-1\",\"batch_size\":64,\"beta_entropy\":0.01,\"discount_factor\":0.995,\"e_greedy_value\":0.05,\"epsilon_steps\":6000,\"exploration_type\":\"categorical\",\"loss_type\":\"huber\",\"lr\":3e-05,\"model_metadata_s3_key\":\"s3://bucket/custom_files/model_metadata.json\",\"num_episodes_between_training\":36,\"num_epochs\":10,\"pretrained_checkpoint\":\"last\",\"pretrained_s3_bucket\":\"bucket\",\"pretrained_s3_prefix\":\"rl-deepracer-sagemaker\",\"s3_bucket\":\"bucket\",\"s3_prefix\":\"rl-deepracer-1\",\"sac_alpha\":0.2,\"stack_size\":1,\"term_cond_avg_score\":100000.0,\"term_cond_max_episodes\":999999},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rl-deepracer-1\",\"log_level\":20,\"master_hostname\":\"algo-1-7mq0q\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://bucket/rl-deepracer-1/source/sourcedir.tar.gz\",\"module_name\":\"training_worker\",\"network_interface_name\":\"eth0\",\"num_cpus\":12,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-7mq0q\",\"hosts\":[\"algo-1-7mq0q\"]},\"user_entry_point\":\"training_worker.py\"}\n",
      "SM_USER_ARGS=[\"--RLCOACH_PRESET\",\"deepracer\",\"--aws_region\",\"us-east-1\",\"--batch_size\",\"64\",\"--beta_entropy\",\"0.01\",\"--discount_factor\",\"0.995\",\"--e_greedy_value\",\"0.05\",\"--epsilon_steps\",\"6000\",\"--exploration_type\",\"categorical\",\"--loss_type\",\"huber\",\"--lr\",\"3e-05\",\"--model_metadata_s3_key\",\"s3://bucket/custom_files/model_metadata.json\",\"--num_episodes_between_training\",\"36\",\"--num_epochs\",\"10\",\"--pretrained_checkpoint\",\"last\",\"--pretrained_s3_bucket\",\"bucket\",\"--pretrained_s3_prefix\",\"rl-deepracer-sagemaker\",\"--s3_bucket\",\"bucket\",\"--s3_prefix\",\"rl-deepracer-1\",\"--sac_alpha\",\"0.2\",\"--stack_size\",\"1\",\"--term_cond_avg_score\",\"100000.0\",\"--term_cond_max_episodes\",\"999999\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_S3_BUCKET=bucket\n",
      "SM_HP_S3_PREFIX=rl-deepracer-1\n",
      "SM_HP_AWS_REGION=us-east-1\n",
      "SM_HP_MODEL_METADATA_S3_KEY=s3://bucket/custom_files/model_metadata.json\n",
      "SM_HP_RLCOACH_PRESET=deepracer\n",
      "SM_HP_PRETRAINED_S3_BUCKET=bucket\n",
      "SM_HP_PRETRAINED_S3_PREFIX=rl-deepracer-sagemaker\n",
      "SM_HP_PRETRAINED_CHECKPOINT=last\n",
      "SM_HP_BATCH_SIZE=64\n",
      "SM_HP_BETA_ENTROPY=0.01\n",
      "SM_HP_DISCOUNT_FACTOR=0.995\n",
      "SM_HP_E_GREEDY_VALUE=0.05\n",
      "SM_HP_EPSILON_STEPS=6000\n",
      "SM_HP_EXPLORATION_TYPE=categorical\n",
      "SM_HP_LOSS_TYPE=huber\n",
      "SM_HP_LR=3e-05\n",
      "SM_HP_NUM_EPISODES_BETWEEN_TRAINING=36\n",
      "SM_HP_NUM_EPOCHS=10\n",
      "SM_HP_STACK_SIZE=1\n",
      "SM_HP_TERM_COND_AVG_SCORE=100000.0\n",
      "SM_HP_TERM_COND_MAX_EPISODES=999999\n",
      "SM_HP_SAC_ALPHA=0.2\n",
      "PYTHONPATH=/usr/local/bin:/opt/amazon:/opt/ml/code:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\n",
      "Invoking script with the following command:\n",
      "\n",
      "/usr/bin/python training_worker.py --RLCOACH_PRESET deepracer --aws_region us-east-1 --batch_size 64 --beta_entropy 0.01 --discount_factor 0.995 --e_greedy_value 0.05 --epsilon_steps 6000 --exploration_type categorical --loss_type huber --lr 3e-05 --model_metadata_s3_key s3://bucket/custom_files/model_metadata.json --num_episodes_between_training 36 --num_epochs 10 --pretrained_checkpoint last --pretrained_s3_bucket bucket --pretrained_s3_prefix rl-deepracer-sagemaker --s3_bucket bucket --s3_prefix rl-deepracer-1 --sac_alpha 0.2 --stack_size 1 --term_cond_avg_score 100000.0 --term_cond_max_episodes 999999\n",
      "\n",
      "\n",
      "Using the following hyper-parameters\n",
      "{\n",
      "  \"batch_size\": 64,\n",
      "  \"beta_entropy\": 0.01,\n",
      "  \"discount_factor\": 0.995,\n",
      "  \"e_greedy_value\": 0.05,\n",
      "  \"epsilon_steps\": 6000,\n",
      "  \"exploration_type\": \"categorical\",\n",
      "  \"loss_type\": \"huber\",\n",
      "  \"lr\": 3e-05,\n",
      "  \"num_episodes_between_training\": 36,\n",
      "  \"num_epochs\": 10,\n",
      "  \"stack_size\": 1,\n",
      "  \"term_cond_avg_score\": 100000.0,\n",
      "  \"term_cond_max_episodes\": 999999\n",
      "}\n",
      "## Creating graph - name: MultiAgentGraphManager\n",
      "## Start physics before creating graph\n",
      "## Create graph\n",
      "## Creating agent - name: agent\n",
      "[RL] Created agent loggers\n",
      "[RL] Dynamic import of memory:  \"DeepRacerMemoryParameters\" {\n",
      "    \"load_memory_from_file_path\": null,\n",
      "    \"max_size\": [\n",
      "        \"<MemoryGranularity.Transitions: 0>\",\n",
      "        1000000\n",
      "    ],\n",
      "    \"n_step\": -1,\n",
      "    \"shared_memory\": false,\n",
      "    \"train_to_eval_ratio\": 1\n",
      "}\n",
      "\n",
      "[RL] Dynamically imported of memory <markov.memories.deepracer_memory.DeepRacerMemory object at 0x7fb770dd3be0>\n",
      "[RL] Setting devices\n",
      "[RL] Setting filters\n",
      "[RL] Setting filter devices: numpy\n",
      "[RL] Setting Phase\n",
      "[RL] After setting Phase\n",
      "[RL] Setting signals\n",
      "[RL] Agent init successful\n",
      "[RL] ActorCriticAgent init\n",
      "[RL] ActorCriticAgent  init successful\n",
      "## Created agent: agent\n",
      "## Stop physics after creating graph\n",
      "## Creating session\n",
      "Creating regular session\n",
      "21:signal-handler (1634002965) Received SIGTERM scheduling shutdown...\n",
      "/usr/local/bin/start.sh: line 24:    22 Terminated              LD_PRELOAD=/libchangehostname.so xvfb-run --auto-servernum -s \"-screen 0 1024x768x16\" train\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please press u to previous or d for next log or x to quit: d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:C 14 Aug 2021 16:19:04.712 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n",
      "21:C 14 Aug 2021 16:19:04.712 # Redis version=6.2.2, bits=64, commit=00000000, modified=0, pid=21, just started\n",
      "21:C 14 Aug 2021 16:19:04.712 # Configuration loaded\n",
      "21:M 14 Aug 2021 16:19:04.712 * monotonic clock: POSIX clock_gettime\n",
      "                _._                                                  \n",
      "           _.-``__ ''-._                                             \n",
      "      _.-``    `.  `_.  ''-._           Redis 6.2.2 (00000000/0) 64 bit\n",
      "  .-`` .-```.  ```\\/    _.,_ ''-._                                  \n",
      " (    '      ,       .-`  | `,    )     Running in standalone mode\n",
      " |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n",
      " |    `-._   `._    /     _.-'    |     PID: 21\n",
      "  `-._    `-._  `-./  _.-'    _.-'                                   \n",
      " |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n",
      " |    `-._`-._        _.-'_.-'    |           https://redis.io       \n",
      "  `-._    `-._`-.__.-'_.-'    _.-'                                   \n",
      " |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n",
      " |    `-._`-._        _.-'_.-'    |                                  \n",
      "  `-._    `-._`-.__.-'_.-'    _.-'                                   \n",
      "      `-._    `-.__.-'    _.-'                                       \n",
      "          `-._        _.-'                                           \n",
      "              `-.__.-'                                               \n",
      "\n",
      "21:M 14 Aug 2021 16:19:04.713 # Server initialized\n",
      "21:M 14 Aug 2021 16:19:04.713 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n",
      "21:M 14 Aug 2021 16:19:04.713 * Ready to accept connections\n",
      "2021-08-14 16:19:05.480575: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "2021-08-14 16:19:06,583 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "2021-08-14 16:19:06,747 sagemaker-containers INFO     Invoking user script\n",
      "\n",
      "Training Env:\n",
      "\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator\": \"RLEstimator\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1-yokww\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1-yokww\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"s3_bucket\": \"bucket\",\n",
      "        \"s3_prefix\": \"rl-deepracer-sagemaker\",\n",
      "        \"aws_region\": \"us-east-1\",\n",
      "        \"model_metadata_s3_key\": \"s3://bucket/custom_files/model_metadata.json\",\n",
      "        \"RLCOACH_PRESET\": \"deepracer\",\n",
      "        \"batch_size\": 64,\n",
      "        \"beta_entropy\": 0.01,\n",
      "        \"discount_factor\": 0.995,\n",
      "        \"e_greedy_value\": 0.05,\n",
      "        \"epsilon_steps\": 10000,\n",
      "        \"exploration_type\": \"categorical\",\n",
      "        \"loss_type\": \"huber\",\n",
      "        \"lr\": 0.0003,\n",
      "        \"num_episodes_between_training\": 20,\n",
      "        \"num_epochs\": 10,\n",
      "        \"stack_size\": 1,\n",
      "        \"term_cond_avg_score\": 350.0,\n",
      "        \"term_cond_max_episodes\": 1000,\n",
      "        \"sac_alpha\": 0.2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rl-deepracer-sagemaker\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1-yokww\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://bucket/rl-deepracer-sagemaker/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"training_worker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 12,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1-yokww\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1-yokww\"\n",
      "        ]\n",
      "    },\n",
      "    \"user_entry_point\": \"training_worker.py\"\n",
      "}\n",
      "\n",
      "Environment variables:\n",
      "\n",
      "SM_HOSTS=[\"algo-1-yokww\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"RLCOACH_PRESET\":\"deepracer\",\"aws_region\":\"us-east-1\",\"batch_size\":64,\"beta_entropy\":0.01,\"discount_factor\":0.995,\"e_greedy_value\":0.05,\"epsilon_steps\":10000,\"exploration_type\":\"categorical\",\"loss_type\":\"huber\",\"lr\":0.0003,\"model_metadata_s3_key\":\"s3://bucket/custom_files/model_metadata.json\",\"num_episodes_between_training\":20,\"num_epochs\":10,\"s3_bucket\":\"bucket\",\"s3_prefix\":\"rl-deepracer-sagemaker\",\"sac_alpha\":0.2,\"stack_size\":1,\"term_cond_avg_score\":350.0,\"term_cond_max_episodes\":1000}\n",
      "SM_USER_ENTRY_POINT=training_worker.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\n",
      "SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-yokww\",\"hosts\":[\"algo-1-yokww\"]}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1-yokww\n",
      "SM_MODULE_NAME=training_worker\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=12\n",
      "SM_NUM_GPUS=1\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://bucket/rl-deepracer-sagemaker/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1-yokww\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-yokww\"],\"hyperparameters\":{\"RLCOACH_PRESET\":\"deepracer\",\"aws_region\":\"us-east-1\",\"batch_size\":64,\"beta_entropy\":0.01,\"discount_factor\":0.995,\"e_greedy_value\":0.05,\"epsilon_steps\":10000,\"exploration_type\":\"categorical\",\"loss_type\":\"huber\",\"lr\":0.0003,\"model_metadata_s3_key\":\"s3://bucket/custom_files/model_metadata.json\",\"num_episodes_between_training\":20,\"num_epochs\":10,\"s3_bucket\":\"bucket\",\"s3_prefix\":\"rl-deepracer-sagemaker\",\"sac_alpha\":0.2,\"stack_size\":1,\"term_cond_avg_score\":350.0,\"term_cond_max_episodes\":1000},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rl-deepracer-sagemaker\",\"log_level\":20,\"master_hostname\":\"algo-1-yokww\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://bucket/rl-deepracer-sagemaker/source/sourcedir.tar.gz\",\"module_name\":\"training_worker\",\"network_interface_name\":\"eth0\",\"num_cpus\":12,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-yokww\",\"hosts\":[\"algo-1-yokww\"]},\"user_entry_point\":\"training_worker.py\"}\n",
      "SM_USER_ARGS=[\"--RLCOACH_PRESET\",\"deepracer\",\"--aws_region\",\"us-east-1\",\"--batch_size\",\"64\",\"--beta_entropy\",\"0.01\",\"--discount_factor\",\"0.995\",\"--e_greedy_value\",\"0.05\",\"--epsilon_steps\",\"10000\",\"--exploration_type\",\"categorical\",\"--loss_type\",\"huber\",\"--lr\",\"0.0003\",\"--model_metadata_s3_key\",\"s3://bucket/custom_files/model_metadata.json\",\"--num_episodes_between_training\",\"20\",\"--num_epochs\",\"10\",\"--s3_bucket\",\"bucket\",\"--s3_prefix\",\"rl-deepracer-sagemaker\",\"--sac_alpha\",\"0.2\",\"--stack_size\",\"1\",\"--term_cond_avg_score\",\"350.0\",\"--term_cond_max_episodes\",\"1000\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_S3_BUCKET=bucket\n",
      "SM_HP_S3_PREFIX=rl-deepracer-sagemaker\n",
      "SM_HP_AWS_REGION=us-east-1\n",
      "SM_HP_MODEL_METADATA_S3_KEY=s3://bucket/custom_files/model_metadata.json\n",
      "SM_HP_RLCOACH_PRESET=deepracer\n",
      "SM_HP_BATCH_SIZE=64\n",
      "SM_HP_BETA_ENTROPY=0.01\n",
      "SM_HP_DISCOUNT_FACTOR=0.995\n",
      "SM_HP_E_GREEDY_VALUE=0.05\n",
      "SM_HP_EPSILON_STEPS=10000\n",
      "SM_HP_EXPLORATION_TYPE=categorical\n",
      "SM_HP_LOSS_TYPE=huber\n",
      "SM_HP_LR=0.0003\n",
      "SM_HP_NUM_EPISODES_BETWEEN_TRAINING=20\n",
      "SM_HP_NUM_EPOCHS=10\n",
      "SM_HP_STACK_SIZE=1\n",
      "SM_HP_TERM_COND_AVG_SCORE=350.0\n",
      "SM_HP_TERM_COND_MAX_EPISODES=1000\n",
      "SM_HP_SAC_ALPHA=0.2\n",
      "PYTHONPATH=/usr/local/bin:/opt/amazon:/opt/ml/code:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\n",
      "Invoking script with the following command:\n",
      "\n",
      "/usr/bin/python3 training_worker.py --RLCOACH_PRESET deepracer --aws_region us-east-1 --batch_size 64 --beta_entropy 0.01 --discount_factor 0.995 --e_greedy_value 0.05 --epsilon_steps 10000 --exploration_type categorical --loss_type huber --lr 0.0003 --model_metadata_s3_key s3://bucket/custom_files/model_metadata.json --num_episodes_between_training 20 --num_epochs 10 --s3_bucket bucket --s3_prefix rl-deepracer-sagemaker --sac_alpha 0.2 --stack_size 1 --term_cond_avg_score 350.0 --term_cond_max_episodes 1000\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "WARNING:tensorflow:From training_worker.py:47: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From training_worker.py:47: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
      "\n",
      "Training Worker Args: Namespace(aws_region='us-east-1', checkpoint_dir='./checkpoint_sagemaker', environment_s3_key=None, framework='tensorflow', model_metadata_s3_key='s3://bucket/custom_files/model_metadata.json', preset_s3_key=None, pretrained_checkpoint='best', pretrained_checkpoint_dir='./pretrained_checkpoint_sagemaker', pretrained_s3_bucket=None, pretrained_s3_prefix='sagemaker', s3_bucket='bucket', s3_endpoint_url='http://minio:9000', s3_prefix='rl-deepracer-sagemaker')\n",
      "S3 bucket: bucket \n",
      " S3 prefix: rl-deepracer-sagemaker \n",
      " S3 endpoint URL: http://minio:9000\n",
      "[s3] Successfully downloaded model metadata                  from s3 key custom_files/model_metadata.json to local ./custom_files/agent/model_metadata.json.\n",
      "Sensor list ['FRONT_FACING_CAMERA'], network DEEP_CONVOLUTIONAL_NETWORK_SHALLOW, simapp_version 3.0, training_algorithm clipped_ppo, action_space_type discrete lidar_config {'num_sectors': 8, 'num_values_per_sector': 8, 'clipping_dist': 2.0}\n",
      "Action space from file: [{'steering_angle': -30, 'speed': 0.6}, {'steering_angle': -15, 'speed': 0.6}, {'steering_angle': 0, 'speed': 0.6}, {'steering_angle': 15, 'speed': 0.6}, {'steering_angle': 30, 'speed': 0.6}]\n",
      "Using the following hyper-parameters\n",
      "{\n",
      "  \"batch_size\": 64,\n",
      "  \"beta_entropy\": 0.01,\n",
      "  \"discount_factor\": 0.995,\n",
      "  \"e_greedy_value\": 0.05,\n",
      "  \"epsilon_steps\": 10000,\n",
      "  \"exploration_type\": \"categorical\",\n",
      "  \"loss_type\": \"huber\",\n",
      "  \"lr\": 0.0003,\n",
      "  \"num_episodes_between_training\": 20,\n",
      "  \"num_epochs\": 10,\n",
      "  \"stack_size\": 1,\n",
      "  \"term_cond_avg_score\": 350.0,\n",
      "  \"term_cond_max_episodes\": 1000\n",
      "}\n",
      "[s3] Successfully uploaded hyperparameters to                  s3 bucket bucket with s3 key rl-deepracer-sagemaker/ip/hyperparameters.json.\n",
      "Hostname: algo-1-yokww\n",
      "[s3] Successfully uploaded ip address to                  s3 bucket bucket with s3 key rl-deepracer-sagemaker/ip/ip.json.\n",
      "[s3] Successfully uploaded ip done to                  s3 bucket bucket with s3 key rl-deepracer-sagemaker/ip/done.\n",
      "## Creating graph - name: MultiAgentGraphManager\n",
      "## Start physics before creating graph\n",
      "## Create graph\n",
      "## Creating agent - name: agent\n",
      "[RL] Created agent loggers\n",
      "[RL] Dynamic import of memory:  \"DeepRacerMemoryParameters\" {\n",
      "    \"load_memory_from_file_path\": null,\n",
      "    \"max_size\": [\n",
      "        \"<MemoryGranularity.Transitions: 0>\",\n",
      "        1000000\n",
      "    ],\n",
      "    \"n_step\": -1,\n",
      "    \"shared_memory\": false,\n",
      "    \"train_to_eval_ratio\": 1\n",
      "}\n",
      "\n",
      "[RL] Dynamically imported of memory <markov.memories.deepracer_memory.DeepRacerMemory object at 0x7f4854d160f0>\n",
      "[RL] Setting devices\n",
      "[RL] Setting filters\n",
      "[RL] Setting filter devices: numpy\n",
      "[RL] Setting Phase\n",
      "[RL] After setting Phase\n",
      "[RL] Setting signals\n",
      "[RL] Agent init successful\n",
      "[RL] ActorCriticAgent init\n",
      "[RL] ActorCriticAgent  init successful\n",
      "## Created agent: agent\n",
      "## Stop physics after creating graph\n",
      "## Creating session\n",
      "Creating regular session\n",
      "2021-08-14 16:20:01.774813: W tensorflow/core/common_runtime/colocation_graph.cc:983] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
      "Identity: GPU CPU XLA_CPU XLA_GPU \n",
      "VariableV2: CPU \n",
      "Assign: GPU CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  main_level/agent/main/online/Variable (VariableV2) /device:GPU:0\n",
      "  main_level/agent/main/online/Variable/Assign (Assign) /device:GPU:0\n",
      "  main_level/agent/main/online/Variable/read (Identity) /device:GPU:0\n",
      "  main_level/agent/main/online/Assign (Assign) /device:GPU:0\n",
      "\n",
      "2021-08-14 16:20:01.775481: W tensorflow/core/common_runtime/colocation_graph.cc:983] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
      "Identity: GPU CPU XLA_CPU XLA_GPU \n",
      "VariableV2: CPU \n",
      "Assign: GPU CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  main_level/agent/main/target/Variable (VariableV2) /device:GPU:0\n",
      "  main_level/agent/main/target/Variable/Assign (Assign) /device:GPU:0\n",
      "  main_level/agent/main/target/Variable/read (Identity) /device:GPU:0\n",
      "  main_level/agent/main/target/Assign (Assign) /device:GPU:0\n",
      "\n",
      "Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/0_Step-0.ckpt']\n",
      "[s3] Successfully uploaded .lock to                      s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.lock.\n",
      "Uploaded 3 files for checkpoint 0\n",
      "[s3] Successfully uploaded coach checkpoint to                   s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.coach_checkpoint.\n",
      "Unable to find deepracer checkpoint json\n",
      "Unable to find the best deepracer checkpoint number. Getting the last checkpoint number\n",
      "Unable to find deepracer checkpoint json\n",
      "Unable to find the last deepracer checkpoint number.\n",
      "Unable to find deepracer checkpoint json\n",
      "Unable to find the last deepracer checkpoint number.\n",
      "saved intermediate frozen graph: rl-deepracer-sagemaker/model/model_0.pb\n",
      "Best checkpoint number: -1, Last checkpoint number: -1\n",
      "Copying the frozen checkpoint from ./frozen_models/agent/model_0.pb to /opt/ml/model/agent/model.pb.\n",
      "Unable to find deepracer checkpoint json\n",
      "[s3] Successfully uploaded .lock to                      s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.lock.\n",
      "[s3] Successfully uploaded .ready to                      s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.ready.\n",
      "DoorMan: installing SIGINT, SIGTERM\n",
      "Training> Name=main_level/agent, Worker=0, Episode=1, Total reward=29.25, Steps=55, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=2, Total reward=11.69, Steps=86, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=3, Total reward=63.85, Steps=223, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=4, Total reward=14.15, Steps=260, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=5, Total reward=13.29, Steps=297, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=6, Total reward=19.39, Steps=343, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=7, Total reward=40.51, Steps=424, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=8, Total reward=117.45, Steps=584, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=9, Total reward=17.79, Steps=630, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=10, Total reward=44.27, Steps=696, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=11, Total reward=28.87, Steps=747, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=12, Total reward=12.89, Steps=780, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=13, Total reward=28.17, Steps=840, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=14, Total reward=13.45, Steps=879, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=15, Total reward=40.23, Steps=962, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=16, Total reward=31.25, Steps=1019, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=17, Total reward=10.35, Steps=1049, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=18, Total reward=39.75, Steps=1114, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=19, Total reward=12.55, Steps=1152, Training iteration=0\n",
      "Training> Name=main_level/agent, Worker=0, Episode=20, Total reward=13.01, Steps=1184, Training iteration=0\n",
      "Policy training> Surrogate loss=0.0030227217357605696, KL divergence=0.014256242662668228, Entropy=1.5944823026657104, training epoch=0, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.005466195289045572, KL divergence=0.006673288531601429, Entropy=1.601564884185791, training epoch=1, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.007419867441058159, KL divergence=0.006553119979798794, Entropy=1.6007776260375977, training epoch=2, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.0023141438141465187, KL divergence=0.005342716816812754, Entropy=1.602354645729065, training epoch=3, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.007357948459684849, KL divergence=0.00601132633164525, Entropy=1.6018521785736084, training epoch=4, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.010249638929963112, KL divergence=0.008039036765694618, Entropy=1.5996102094650269, training epoch=5, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.0030386464204639196, KL divergence=0.0023423293605446815, Entropy=1.6066149473190308, training epoch=6, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.01288285106420517, KL divergence=0.00725744990631938, Entropy=1.6003813743591309, training epoch=7, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.006373099982738495, KL divergence=0.007831783965229988, Entropy=1.6002883911132812, training epoch=8, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.00640040822327137, KL divergence=0.005801786202937365, Entropy=1.6031174659729004, training epoch=9, learning_rate=0.0003\n",
      "Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/1_Step-1184.ckpt']\n",
      "[s3] Successfully uploaded .lock to                      s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.lock.\n",
      "Uploaded 3 files for checkpoint 1\n",
      "[s3] Successfully uploaded coach checkpoint to                   s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.coach_checkpoint.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "saved intermediate frozen graph: rl-deepracer-sagemaker/model/model_1.pb\n",
      "Best checkpoint number: 0, Last checkpoint number: 0\n",
      "Copying the frozen checkpoint from ./frozen_models/agent/model_0.pb to /opt/ml/model/agent/model.pb.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "Training> Name=main_level/agent, Worker=0, Episode=21, Total reward=19.25, Steps=1231, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=22, Total reward=18.47, Steps=1272, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=23, Total reward=25.17, Steps=1319, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=24, Total reward=11.73, Steps=1354, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=25, Total reward=18.23, Steps=1397, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=26, Total reward=28.05, Steps=1456, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=27, Total reward=27.71, Steps=1537, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=28, Total reward=12.51, Steps=1573, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=29, Total reward=39.63, Steps=1639, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=30, Total reward=64.97, Steps=1731, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=31, Total reward=18.37, Steps=1783, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=32, Total reward=28.79, Steps=1841, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=33, Total reward=43.63, Steps=1944, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=34, Total reward=13.21, Steps=1986, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=35, Total reward=49.31, Steps=2058, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=36, Total reward=23.27, Steps=2101, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=37, Total reward=16.03, Steps=2138, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=38, Total reward=30.56, Steps=2192, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=39, Total reward=11.37, Steps=2225, Training iteration=1\n",
      "Training> Name=main_level/agent, Worker=0, Episode=40, Total reward=14.89, Steps=2264, Training iteration=1\n",
      "Policy training> Surrogate loss=-0.0026982822455465794, KL divergence=0.0009977451991289854, Entropy=1.6053285598754883, training epoch=0, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=0.004541609436273575, KL divergence=0.006813501939177513, Entropy=1.598737359046936, training epoch=1, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.0031638802029192448, KL divergence=0.010332521051168442, Entropy=1.5945384502410889, training epoch=2, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.007535094395279884, KL divergence=0.007235686294734478, Entropy=1.6000032424926758, training epoch=3, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.006670419126749039, KL divergence=0.009703271090984344, Entropy=1.598078727722168, training epoch=4, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.00471852533519268, KL divergence=0.008637221530079842, Entropy=1.5989203453063965, training epoch=5, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.00560069689527154, KL divergence=0.009269450791180134, Entropy=1.5962018966674805, training epoch=6, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.020594950765371323, KL divergence=0.012343854643404484, Entropy=1.5931750535964966, training epoch=7, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.020626280456781387, KL divergence=0.009247955866158009, Entropy=1.5937378406524658, training epoch=8, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.0319417268037796, KL divergence=0.007667005993425846, Entropy=1.5942952632904053, training epoch=9, learning_rate=0.0003\n",
      "Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/2_Step-2264.ckpt']\n",
      "[s3] Successfully uploaded .lock to                      s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.lock.\n",
      "Uploaded 3 files for checkpoint 2\n",
      "[s3] Successfully uploaded coach checkpoint to                   s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.coach_checkpoint.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "saved intermediate frozen graph: rl-deepracer-sagemaker/model/model_2.pb\n",
      "Best checkpoint number: 0, Last checkpoint number: 0\n",
      "Copying the frozen checkpoint from ./frozen_models/agent/model_0.pb to /opt/ml/model/agent/model.pb.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "Training> Name=main_level/agent, Worker=0, Episode=41, Total reward=25.73, Steps=2324, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=42, Total reward=21.65, Steps=2365, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=43, Total reward=24.11, Steps=2417, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=44, Total reward=8.99, Steps=2443, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=45, Total reward=34.09, Steps=2507, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=46, Total reward=18.83, Steps=2564, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=47, Total reward=94.95, Steps=2745, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=48, Total reward=71.81, Steps=2880, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=49, Total reward=15.25, Steps=2923, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=50, Total reward=45.29, Steps=3016, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=51, Total reward=46.43, Steps=3084, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=52, Total reward=13.39, Steps=3123, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=53, Total reward=54.13, Steps=3224, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=54, Total reward=11.19, Steps=3258, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=55, Total reward=48.03, Steps=3349, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=56, Total reward=22.25, Steps=3390, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=57, Total reward=41.97, Steps=3491, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=58, Total reward=20.51, Steps=3541, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=59, Total reward=14.73, Steps=3584, Training iteration=2\n",
      "Training> Name=main_level/agent, Worker=0, Episode=60, Total reward=60.55, Steps=3669, Training iteration=2\n",
      "Policy training> Surrogate loss=0.004994193557649851, KL divergence=0.006141641177237034, Entropy=1.588555097579956, training epoch=0, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=0.0005093642394058406, KL divergence=0.006784351076930761, Entropy=1.591269850730896, training epoch=1, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.011753877624869347, KL divergence=0.010273660533130169, Entropy=1.5820432901382446, training epoch=2, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.029144475236535072, KL divergence=0.008237573318183422, Entropy=1.5877751111984253, training epoch=3, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.01563778892159462, KL divergence=0.01263502985239029, Entropy=1.5805584192276, training epoch=4, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.032533079385757446, KL divergence=0.010532082058489323, Entropy=1.5845998525619507, training epoch=5, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.03573748841881752, KL divergence=0.012263338081538677, Entropy=1.5843003988265991, training epoch=6, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.04891166090965271, KL divergence=0.017422674223780632, Entropy=1.5742565393447876, training epoch=7, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.023968322202563286, KL divergence=0.012620199471712112, Entropy=1.5822677612304688, training epoch=8, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.03980838134884834, KL divergence=0.016143955290317535, Entropy=1.5766149759292603, training epoch=9, learning_rate=0.0003\n",
      "Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/3_Step-3669.ckpt']\n",
      "[s3] Successfully uploaded .lock to                      s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.lock.\n",
      "Uploaded 3 files for checkpoint 3\n",
      "[s3] Successfully uploaded coach checkpoint to                   s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.coach_checkpoint.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "saved intermediate frozen graph: rl-deepracer-sagemaker/model/model_3.pb\n",
      "Best checkpoint number: 1, Last checkpoint number: 1\n",
      "Copying the frozen checkpoint from ./frozen_models/agent/model_1.pb to /opt/ml/model/agent/model.pb.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "Training> Name=main_level/agent, Worker=0, Episode=61, Total reward=58.73, Steps=3785, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=62, Total reward=12.15, Steps=3817, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=63, Total reward=34.03, Steps=3878, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=64, Total reward=10.59, Steps=3906, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=65, Total reward=28.49, Steps=3973, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=66, Total reward=16.75, Steps=4016, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=67, Total reward=106.93, Steps=4193, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=68, Total reward=86.97, Steps=4334, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=69, Total reward=84.45, Steps=4470, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=70, Total reward=91.37, Steps=4633, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=71, Total reward=34.73, Steps=4720, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=72, Total reward=11.61, Steps=4754, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=73, Total reward=75.15, Steps=4879, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=74, Total reward=64.97, Steps=4985, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=75, Total reward=42.31, Steps=5074, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=76, Total reward=19.03, Steps=5118, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=77, Total reward=13.13, Steps=5150, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=78, Total reward=43.95, Steps=5235, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=79, Total reward=13.49, Steps=5273, Training iteration=3\n",
      "Training> Name=main_level/agent, Worker=0, Episode=80, Total reward=14.51, Steps=5308, Training iteration=3\n",
      "Policy training> Surrogate loss=-0.004460678901523352, KL divergence=0.009032269939780235, Entropy=1.5613815784454346, training epoch=0, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.02389002963900566, KL divergence=0.01560785248875618, Entropy=1.5474252700805664, training epoch=1, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.020786307752132416, KL divergence=0.012648353353142738, Entropy=1.561170220375061, training epoch=2, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.03499799966812134, KL divergence=0.015898678451776505, Entropy=1.5507949590682983, training epoch=3, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.041954703629016876, KL divergence=0.016033535823225975, Entropy=1.5482068061828613, training epoch=4, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.050995536148548126, KL divergence=0.019411323592066765, Entropy=1.5437971353530884, training epoch=5, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.0546637624502182, KL divergence=0.020904691889882088, Entropy=1.5451674461364746, training epoch=6, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.05887733772397041, KL divergence=0.020802341401576996, Entropy=1.5434547662734985, training epoch=7, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.06141280755400658, KL divergence=0.023543255403637886, Entropy=1.5406641960144043, training epoch=8, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.06967534869909286, KL divergence=0.026794979348778725, Entropy=1.5405349731445312, training epoch=9, learning_rate=0.0003\n",
      "Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/4_Step-5308.ckpt']\n",
      "[s3] Successfully uploaded .lock to                      s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.lock.\n",
      "Uploaded 3 files for checkpoint 4\n",
      "[s3] Successfully uploaded coach checkpoint to                   s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.coach_checkpoint.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "saved intermediate frozen graph: rl-deepracer-sagemaker/model/model_4.pb\n",
      "Best checkpoint number: 2, Last checkpoint number: 2\n",
      "Copying the frozen checkpoint from ./frozen_models/agent/model_2.pb to /opt/ml/model/agent/model.pb.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "Deleting the frozen models in s3 for the iterations: {'0'}\n",
      "Training> Name=main_level/agent, Worker=0, Episode=81, Total reward=38.95, Steps=5369, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=82, Total reward=14.07, Steps=5412, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=83, Total reward=145.61, Steps=5654, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=84, Total reward=137.53, Steps=5894, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=85, Total reward=70.41, Steps=6036, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=86, Total reward=109.07, Steps=6199, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=87, Total reward=187.23, Steps=6495, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=88, Total reward=107.77, Steps=6638, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=89, Total reward=125.91, Steps=6838, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=90, Total reward=47.23, Steps=6920, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=91, Total reward=77.77, Steps=7054, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=92, Total reward=15.75, Steps=7092, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=93, Total reward=45.61, Steps=7177, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=94, Total reward=86.49, Steps=7349, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=95, Total reward=32.65, Steps=7411, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=96, Total reward=25.55, Steps=7488, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=97, Total reward=15.13, Steps=7527, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=98, Total reward=24.05, Steps=7582, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=99, Total reward=25.55, Steps=7629, Training iteration=4\n",
      "Training> Name=main_level/agent, Worker=0, Episode=100, Total reward=13.81, Steps=7674, Training iteration=4\n",
      "2021-08-14 16:37:09.702634: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2021-08-14 16:37:19.745155: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.86GiB (rounded to 2002681856).  Current allocation summary follows.\n",
      "2021-08-14 16:37:19.745410: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ****************_________________________________***************************************************\n",
      "2021-08-14 16:37:29.747718: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.86GiB (rounded to 2002681856).  Current allocation summary follows.\n",
      "2021-08-14 16:37:29.747992: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ****************_________________________________***************************************************\n",
      "2021-08-14 16:37:29.981876: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2021-08-14 16:37:40.020991: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB (rounded to 1370570752).  Current allocation summary follows.\n",
      "2021-08-14 16:37:40.021210: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ***********************************______________******_*_****************************x*****x*******\n",
      "2021-08-14 16:37:50.023492: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB (rounded to 1370570752).  Current allocation summary follows.\n",
      "2021-08-14 16:37:50.023770: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ***********************************______________******_*_****************************x*****x*******\n",
      "2021-08-14 16:38:00.052774: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.26GiB (rounded to 1352597504).  Current allocation summary follows.\n",
      "2021-08-14 16:38:00.053047: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ***********************************______________******_*_****************************x*****x*******\n",
      "2021-08-14 16:38:10.055056: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.26GiB (rounded to 1352597504).  Current allocation summary follows.\n",
      "2021-08-14 16:38:10.055270: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ***********************************______________******_*_****************************x*****x*******\n",
      "2021-08-14 16:38:20.057604: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 516.06MiB (rounded to 541130752).  Current allocation summary follows.\n",
      "2021-08-14 16:38:20.057923: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ***********************************______________******_*_****************************x*****x*******\n",
      "2021-08-14 16:38:30.060208: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 516.06MiB (rounded to 541130752).  Current allocation summary follows.\n",
      "2021-08-14 16:38:30.060453: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ***********************************______________******_*_****************************x*****x*******\n",
      "Policy training> Surrogate loss=-0.01108263898640871, KL divergence=0.014023303985595703, Entropy=1.5216087102890015, training epoch=0, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.016055600717663765, KL divergence=0.017487946897745132, Entropy=1.513227939605713, training epoch=1, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.03471360355615616, KL divergence=0.015109643340110779, Entropy=1.5107896327972412, training epoch=2, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.03365941345691681, KL divergence=0.01638166606426239, Entropy=1.5118882656097412, training epoch=3, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.04391603171825409, KL divergence=0.019670609384775162, Entropy=1.504988431930542, training epoch=4, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.0586453340947628, KL divergence=0.019517747685313225, Entropy=1.5071358680725098, training epoch=5, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.058330435305833817, KL divergence=0.02080472558736801, Entropy=1.5063979625701904, training epoch=6, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.07258793711662292, KL divergence=0.023044418543577194, Entropy=1.5004997253417969, training epoch=7, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.08172132819890976, KL divergence=0.025266515091061592, Entropy=1.498465895652771, training epoch=8, learning_rate=0.0003\n",
      "Policy training> Surrogate loss=-0.0881076455116272, KL divergence=0.024797819554805756, Entropy=1.503511905670166, training epoch=9, learning_rate=0.0003\n",
      "Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/5_Step-7674.ckpt']\n",
      "[s3] Successfully uploaded .lock to                      s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.lock.\n",
      "Uploaded 3 files for checkpoint 5\n",
      "[s3] Successfully uploaded coach checkpoint to                   s3 bucket bucket with s3 key rl-deepracer-sagemaker/model/.coach_checkpoint.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "saved intermediate frozen graph: rl-deepracer-sagemaker/model/model_5.pb\n",
      "Best checkpoint number: 3, Last checkpoint number: 3\n",
      "Copying the frozen checkpoint from ./frozen_models/agent/model_3.pb to /opt/ml/model/agent/model.pb.\n",
      "[s3] Successfully downloaded deepracer checkpoint json from                  s3 key rl-deepracer-sagemaker/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.\n",
      "Deleting the frozen models in s3 for the iterations: {'1'}\n",
      "Training> Name=main_level/agent, Worker=0, Episode=101, Total reward=181.59, Steps=8031, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=102, Total reward=13.45, Steps=8063, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=103, Total reward=251.71, Steps=8555, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=104, Total reward=10.53, Steps=8586, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=105, Total reward=175.22, Steps=8999, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=106, Total reward=196.05, Steps=9317, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=107, Total reward=105.47, Steps=9491, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=108, Total reward=136.45, Steps=9754, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=109, Total reward=131.11, Steps=9934, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=110, Total reward=42.23, Steps=10020, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=111, Total reward=21.89, Steps=10074, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=112, Total reward=136.77, Steps=10360, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=113, Total reward=103.87, Steps=10489, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=114, Total reward=269.79, Steps=10977, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=115, Total reward=148.25, Steps=11212, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=116, Total reward=24.41, Steps=11263, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=117, Total reward=23.77, Steps=11306, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=118, Total reward=234.46, Steps=11773, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=119, Total reward=16.83, Steps=11818, Training iteration=5\n",
      "Training> Name=main_level/agent, Worker=0, Episode=120, Total reward=16.97, Steps=11868, Training iteration=5\n",
      "2021-08-14 16:45:30.846428: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 579.03MiB (rounded to 607156992).  Current allocation summary follows.\n",
      "2021-08-14 16:45:30.846613: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ******************************___________________******_*_***_____________************x*****x*******\n",
      "2021-08-14 16:45:30.846637: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at conv_ops.cc:500 : Resource exhausted: OOM when allocating tensor with shape[4194,32,29,39] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2021-08-14 16:45:40.848573: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 579.03MiB (rounded to 607156992).  Current allocation summary follows.\n",
      "2021-08-14 16:45:40.848781: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ******************************___________________******_*_***_____________************x*****x*******\n",
      "2021-08-14 16:45:40.848804: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at conv_ops.cc:500 : Resource exhausted: OOM when allocating tensor with shape[4194,32,29,39] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "{\"simapp_exception\": {\"date\": \"2021-08-14 16:45:42.252206\", \"function\": \"training_worker.py::training_worker::172\", \"message\": \"An error occured while training: 2 root error(s) found.\\n  (0) Resource exhausted: OOM when allocating tensor with shape[4194,32,29,39] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\\n\\t [[node main_level/agent/main/online/network_0/FRONT_FACING_CAMERA/Conv2d_0/Conv2D (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\\n\\n  (1) Resource exhausted: OOM when allocating tensor with shape[4194,32,29,39] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\\n\\t [[node main_level/agent/main/online/network_0/FRONT_FACING_CAMERA/Conv2d_0/Conv2D (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\\n\\n\\t [[main_level/agent/main/online/network_1/ppo_head_0/Maximum/_267]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\\n\\n0 successful operations.\\n0 derived errors ignored.\\n\\nOriginal stack trace for 'main_level/agent/main/online/network_0/FRONT_FACING_CAMERA/Conv2d_0/Conv2D':\\n  File \\\"training_worker.py\\\", line 420, in <module>\\n    main()\\n  File \\\"training_worker.py\\\", line 407, in main\\n    training_algorithm=training_algorithm\\n  File \\\"training_worker.py\\\", line 60, in training_worker\\n    graph_manager.create_graph(task_parameters)\\n  File \\\"/opt/ml/code/markov/multi_agent_coach/multi_agent_graph_manager.py\\\", line 112, in create_graph\\n    self.level_managers, self.environments = self._create_graph(task_parameters)\\n  File \\\"/opt/ml/code/markov/multi_agent_coach/multi_agent_graph_manager.py\\\", line 152, in _create_graph\\n    level_manager = MultiAgentLevelManager(agents=agents, environment=env, name=\\\"main_level\\\", done_condition=self.done_condition)\\n  File \\\"/opt/ml/code/markov/multi_agent_coach/multi_agent_level_manager.py\\\", line 77, in __init__\\n    self.build(spaces_definition)\\n  File \\\"/opt/ml/code/markov/multi_agent_coach/multi_agent_level_manager.py\\\", line 145, in build\\n    agent.set_environment_parameters(spaces)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/agents/agent.py\\\", line 353, in set_environment_parameters\\n    self.init_environment_dependent_modules()\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/agents/agent.py\\\", line 398, in init_environment_dependent_modules\\n    self.networks = self.create_networks()\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/agents/agent.py\\\", line 371, in create_networks\\n    worker_device=self.worker_device)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/network_wrapper.py\\\", line 86, in __init__\\n    network_is_trainable=True)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/general_network.py\\\", line 74, in construct\\n    return construct_on_device()\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/general_network.py\\\", line 59, in construct_on_device\\n    return GeneralTensorFlowNetwork(*args, **kwargs)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/general_network.py\\\", line 126, in __init__\\n    network_is_local, network_is_trainable)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/architecture.py\\\", line 105, in __init__\\n    self.weights = self.get_model()\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/general_network.py\\\", line 262, in get_model\\n    input_placeholder, embedding = input_embedder()\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/embedders/embedder.py\\\", line 89, in __call__\\n    self._build_module()\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/embedders/embedder.py\\\", line 116, in _build_module\\n    is_training=self.is_training)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/layers.py\\\", line 120, in __call__\\n    strides=self.strides, data_format='channels_last', name=name)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\\\", line 330, in new_func\\n    return func(*args, **kwargs)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py\\\", line 424, in conv2d\\n    return layer.apply(inputs)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\\\", line 330, in new_func\\n    return func(*args, **kwargs)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\\\", line 1700, in apply\\n    return self.__call__(inputs, *args, **kwargs)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py\\\", line 548, in __call__\\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\\\", line 854, in __call__\\n    outputs = call_fn(cast_inputs, *args, **kwargs)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\\\", line 234, in wrapper\\n    return converted_call(f, options, args, kwargs)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\\\", line 439, in converted_call\\n    return _call_unconverted(f, args, kwargs, options)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\\\", line 330, in _call_unconverted\\n    return f(*args, **kwargs)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\\\", line 201, in call\\n    outputs = self._convolution_op(inputs, self.kernel)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\\\", line 1176, in __call__\\n    return self.conv_op(inp, filter)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\\\", line 662, in __call__\\n    return self.call(inp, filter)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\\\", line 252, in __call__\\n    name=self.name)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\\\", line 2052, in conv2d\\n    name=name)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\\\", line 1071, in conv2d\\n    data_format=data_format, dilations=dilations, name=name)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\\\", line 794, in _apply_op_helper\\n    op_def=op_def)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\\\", line 513, in new_func\\n    return func(*args, **kwargs)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\\\", line 3357, in create_op\\n    attrs, op_def, compute_device)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\\\", line 3426, in _create_op_internal\\n    op_def=op_def)\\n  File \\\"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\\\", line 1748, in __init__\\n    self._traceback = tf_stack.extract_stack()\\n\", \"exceptionType\": \"training_worker.exceptions\", \"eventType\": \"system_error\", \"errorCode\": \"500\"}}\n",
      "ERROR: FAULT_CODE: 27\n",
      "simapp_exit_gracefully: simapp_exit--1\n",
      "Terminating simapp simulation...\n",
      "simapp_exit_gracefully - callstack trace=Traceback (callstack)\n",
      "  File \"training_worker.py\", line 420, in <module>\n",
      "    main()\n",
      "  File \"training_worker.py\", line 407, in main\n",
      "    training_algorithm=training_algorithm\n",
      "  File \"training_worker.py\", line 172, in training_worker\n",
      "    SIMAPP_EVENT_ERROR_CODE_500)\n",
      "  File \"/opt/ml/code/markov/log_handler/exception_handler.py\", line 74, in log_and_exit\n",
      "    s3_crash_status_file_name=s3_crash_status_file_name)\n",
      "  File \"/opt/ml/code/markov/log_handler/exception_handler.py\", line 179, in simapp_exit_gracefully\n",
      "    callstack_trace = ''.join(traceback.format_stack())\n",
      "\n",
      "simapp_exit_gracefully - exception trace=Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
      "    target_list, run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.\n",
      "  (0) Resource exhausted: OOM when allocating tensor with shape[4194,32,29,39] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node main_level/agent/main/online/network_0/FRONT_FACING_CAMERA/Conv2d_0/Conv2D}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "  (1) Resource exhausted: OOM when allocating tensor with shape[4194,32,29,39] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node main_level/agent/main/online/network_0/FRONT_FACING_CAMERA/Conv2d_0/Conv2D}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "\t [[main_level/agent/main/online/network_1/ppo_head_0/Maximum/_267]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "0 successful operations.\n",
      "0 derived errors ignored.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"training_worker.py\", line 126, in training_worker\n",
      "    graph_manager.train()\n",
      "  File \"/opt/ml/code/markov/multi_agent_coach/multi_agent_graph_manager.py\", line 397, in train\n",
      "    [manager.train() for manager in self.level_managers]\n",
      "  File \"/opt/ml/code/markov/multi_agent_coach/multi_agent_graph_manager.py\", line 397, in <listcomp>\n",
      "    [manager.train() for manager in self.level_managers]\n",
      "  File \"/opt/ml/code/markov/multi_agent_coach/multi_agent_level_manager.py\", line 167, in train\n",
      "    [agent.train() for agent in self.agents.values()]\n",
      "  File \"/opt/ml/code/markov/multi_agent_coach/multi_agent_level_manager.py\", line 167, in <listcomp>\n",
      "    [agent.train() for agent in self.agents.values()]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/agents/clipped_ppo_agent.py\", line 311, in train\n",
      "    self.fill_advantages(batch)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/agents/clipped_ppo_agent.py\", line 153, in fill_advantages\n",
      "    current_state_values = self.networks['main'].online_network.predict(batch.states(network_keys))[0]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/architecture.py\", line 547, in predict\n",
      "    output = self.sess.run(outputs, feed_dict)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.\n",
      "  (0) Resource exhausted: OOM when allocating tensor with shape[4194,32,29,39] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[node main_level/agent/main/online/network_0/FRONT_FACING_CAMERA/Conv2d_0/Conv2D (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "  (1) Resource exhausted: OOM when allocating tensor with shape[4194,32,29,39] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[node main_level/agent/main/online/network_0/FRONT_FACING_CAMERA/Conv2d_0/Conv2D (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "\t [[main_level/agent/main/online/network_1/ppo_head_0/Maximum/_267]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "0 successful operations.\n",
      "0 derived errors ignored.\n",
      "\n",
      "Original stack trace for 'main_level/agent/main/online/network_0/FRONT_FACING_CAMERA/Conv2d_0/Conv2D':\n",
      "  File \"training_worker.py\", line 420, in <module>\n",
      "    main()\n",
      "  File \"training_worker.py\", line 407, in main\n",
      "    training_algorithm=training_algorithm\n",
      "  File \"training_worker.py\", line 60, in training_worker\n",
      "    graph_manager.create_graph(task_parameters)\n",
      "  File \"/opt/ml/code/markov/multi_agent_coach/multi_agent_graph_manager.py\", line 112, in create_graph\n",
      "    self.level_managers, self.environments = self._create_graph(task_parameters)\n",
      "  File \"/opt/ml/code/markov/multi_agent_coach/multi_agent_graph_manager.py\", line 152, in _create_graph\n",
      "    level_manager = MultiAgentLevelManager(agents=agents, environment=env, name=\"main_level\", done_condition=self.done_condition)\n",
      "  File \"/opt/ml/code/markov/multi_agent_coach/multi_agent_level_manager.py\", line 77, in __init__\n",
      "    self.build(spaces_definition)\n",
      "  File \"/opt/ml/code/markov/multi_agent_coach/multi_agent_level_manager.py\", line 145, in build\n",
      "    agent.set_environment_parameters(spaces)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/agents/agent.py\", line 353, in set_environment_parameters\n",
      "    self.init_environment_dependent_modules()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/agents/agent.py\", line 398, in init_environment_dependent_modules\n",
      "    self.networks = self.create_networks()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/agents/agent.py\", line 371, in create_networks\n",
      "    worker_device=self.worker_device)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/network_wrapper.py\", line 86, in __init__\n",
      "    network_is_trainable=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/general_network.py\", line 74, in construct\n",
      "    return construct_on_device()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/general_network.py\", line 59, in construct_on_device\n",
      "    return GeneralTensorFlowNetwork(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/general_network.py\", line 126, in __init__\n",
      "    network_is_local, network_is_trainable)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/architecture.py\", line 105, in __init__\n",
      "    self.weights = self.get_model()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/general_network.py\", line 262, in get_model\n",
      "    input_placeholder, embedding = input_embedder()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/embedders/embedder.py\", line 89, in __call__\n",
      "    self._build_module()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/embedders/embedder.py\", line 116, in _build_module\n",
      "    is_training=self.is_training)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/rl_coach/architectures/tensorflow_components/layers.py\", line 120, in __call__\n",
      "    strides=self.strides, data_format='channels_last', name=name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 330, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py\", line 424, in conv2d\n",
      "    return layer.apply(inputs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 330, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 1700, in apply\n",
      "    return self.__call__(inputs, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py\", line 548, in __call__\n",
      "    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 854, in __call__\n",
      "    outputs = call_fn(cast_inputs, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 234, in wrapper\n",
      "    return converted_call(f, options, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 439, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 330, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 201, in call\n",
      "    outputs = self._convolution_op(inputs, self.kernel)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 1176, in __call__\n",
      "    return self.conv_op(inp, filter)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 662, in __call__\n",
      "    return self.call(inp, filter)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 252, in __call__\n",
      "    name=self.name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 2052, in conv2d\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n",
      "    data_format=data_format, dilations=dilations, name=name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 513, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
      "    attrs, op_def, compute_device)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "\n",
      "simapp_exit_gracefully - skipping s3 upload.\n",
      "simapp_exit_gracefully - Killing pid 1.\n",
      "21:signal-handler (1628959542) Received SIGTERM scheduling shutdown...\n",
      "simapp_exit_gracefully - Killed pid 1.\n",
      "/usr/local/bin/start.sh: line 24:    22 Terminated              LD_PRELOAD=/libchangehostname.so xvfb-run --auto-servernum -s \"-screen 0 1024x768x16\" train\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please press u to previous or d for next log or x to quit: d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:C 22 Aug 2021 03:01:50.175 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n",
      "21:C 22 Aug 2021 03:01:50.175 # Redis version=6.2.2, bits=64, commit=00000000, modified=0, pid=21, just started\n",
      "21:C 22 Aug 2021 03:01:50.175 # Configuration loaded\n",
      "21:M 22 Aug 2021 03:01:50.176 * monotonic clock: POSIX clock_gettime\n",
      "                _._                                                  \n",
      "           _.-``__ ''-._                                             \n",
      "      _.-``    `.  `_.  ''-._           Redis 6.2.2 (00000000/0) 64 bit\n",
      "  .-`` .-```.  ```\\/    _.,_ ''-._                                  \n",
      " (    '      ,       .-`  | `,    )     Running in standalone mode\n",
      " |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n",
      " |    `-._   `._    /     _.-'    |     PID: 21\n",
      "  `-._    `-._  `-./  _.-'    _.-'                                   \n",
      " |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n",
      " |    `-._`-._        _.-'_.-'    |           https://redis.io       \n",
      "  `-._    `-._`-.__.-'_.-'    _.-'                                   \n",
      " |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n",
      " |    `-._`-._        _.-'_.-'    |                                  \n",
      "  `-._    `-._`-.__.-'_.-'    _.-'                                   \n",
      "      `-._    `-.__.-'    _.-'                                       \n",
      "          `-._        _.-'                                           \n",
      "              `-.__.-'                                               \n",
      "\n",
      "21:M 22 Aug 2021 03:01:50.201 # Server initialized\n",
      "21:M 22 Aug 2021 03:01:50.201 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n",
      "21:M 22 Aug 2021 03:01:50.231 * Ready to accept connections\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2021-08-22 03:02:10,507 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "2021-08-22 03:02:10,790 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\n",
      "Training Env:\n",
      "\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator\": \"RLEstimator\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1-swuu8\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1-swuu8\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"s3_bucket\": \"bucket\",\n",
      "        \"s3_prefix\": \"rl-deepracer-sagemaker\",\n",
      "        \"aws_region\": \"us-east-1\",\n",
      "        \"model_metadata_s3_key\": \"s3://bucket/custom_files/model_metadata.json\",\n",
      "        \"RLCOACH_PRESET\": \"deepracer\",\n",
      "        \"pretrained_s3_bucket\": \"bucket\",\n",
      "        \"pretrained_s3_prefix\": \"rl-sagemaker-pretrained\",\n",
      "        \"pretrained_checkpoint\": \"last\",\n",
      "        \"batch_size\": 64,\n",
      "        \"beta_entropy\": 0.01,\n",
      "        \"discount_factor\": 0.995,\n",
      "        \"e_greedy_value\": 0.05,\n",
      "        \"epsilon_steps\": 10000,\n",
      "        \"exploration_type\": \"categorical\",\n",
      "        \"loss_type\": \"huber\",\n",
      "        \"lr\": 0.0003,\n",
      "        \"num_episodes_between_training\": 20,\n",
      "        \"num_epochs\": 10,\n",
      "        \"stack_size\": 1,\n",
      "        \"term_cond_avg_score\": 350.0,\n",
      "        \"term_cond_max_episodes\": 1000,\n",
      "        \"sac_alpha\": 0.2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rl-deepracer-sagemaker\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1-swuu8\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://bucket/rl-deepracer-sagemaker/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"training_worker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 12,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1-swuu8\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1-swuu8\"\n",
      "        ]\n",
      "    },\n",
      "    \"user_entry_point\": \"training_worker.py\"\n",
      "}\n",
      "\n",
      "Environment variables:\n",
      "\n",
      "SM_HOSTS=[\"algo-1-swuu8\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"RLCOACH_PRESET\":\"deepracer\",\"aws_region\":\"us-east-1\",\"batch_size\":64,\"beta_entropy\":0.01,\"discount_factor\":0.995,\"e_greedy_value\":0.05,\"epsilon_steps\":10000,\"exploration_type\":\"categorical\",\"loss_type\":\"huber\",\"lr\":0.0003,\"model_metadata_s3_key\":\"s3://bucket/custom_files/model_metadata.json\",\"num_episodes_between_training\":20,\"num_epochs\":10,\"pretrained_checkpoint\":\"last\",\"pretrained_s3_bucket\":\"bucket\",\"pretrained_s3_prefix\":\"rl-sagemaker-pretrained\",\"s3_bucket\":\"bucket\",\"s3_prefix\":\"rl-deepracer-sagemaker\",\"sac_alpha\":0.2,\"stack_size\":1,\"term_cond_avg_score\":350.0,\"term_cond_max_episodes\":1000}\n",
      "SM_USER_ENTRY_POINT=training_worker.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\n",
      "SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-swuu8\",\"hosts\":[\"algo-1-swuu8\"]}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1-swuu8\n",
      "SM_MODULE_NAME=training_worker\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=12\n",
      "SM_NUM_GPUS=1\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://bucket/rl-deepracer-sagemaker/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1-swuu8\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-swuu8\"],\"hyperparameters\":{\"RLCOACH_PRESET\":\"deepracer\",\"aws_region\":\"us-east-1\",\"batch_size\":64,\"beta_entropy\":0.01,\"discount_factor\":0.995,\"e_greedy_value\":0.05,\"epsilon_steps\":10000,\"exploration_type\":\"categorical\",\"loss_type\":\"huber\",\"lr\":0.0003,\"model_metadata_s3_key\":\"s3://bucket/custom_files/model_metadata.json\",\"num_episodes_between_training\":20,\"num_epochs\":10,\"pretrained_checkpoint\":\"last\",\"pretrained_s3_bucket\":\"bucket\",\"pretrained_s3_prefix\":\"rl-sagemaker-pretrained\",\"s3_bucket\":\"bucket\",\"s3_prefix\":\"rl-deepracer-sagemaker\",\"sac_alpha\":0.2,\"stack_size\":1,\"term_cond_avg_score\":350.0,\"term_cond_max_episodes\":1000},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rl-deepracer-sagemaker\",\"log_level\":20,\"master_hostname\":\"algo-1-swuu8\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://bucket/rl-deepracer-sagemaker/source/sourcedir.tar.gz\",\"module_name\":\"training_worker\",\"network_interface_name\":\"eth0\",\"num_cpus\":12,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-swuu8\",\"hosts\":[\"algo-1-swuu8\"]},\"user_entry_point\":\"training_worker.py\"}\n",
      "SM_USER_ARGS=[\"--RLCOACH_PRESET\",\"deepracer\",\"--aws_region\",\"us-east-1\",\"--batch_size\",\"64\",\"--beta_entropy\",\"0.01\",\"--discount_factor\",\"0.995\",\"--e_greedy_value\",\"0.05\",\"--epsilon_steps\",\"10000\",\"--exploration_type\",\"categorical\",\"--loss_type\",\"huber\",\"--lr\",\"0.0003\",\"--model_metadata_s3_key\",\"s3://bucket/custom_files/model_metadata.json\",\"--num_episodes_between_training\",\"20\",\"--num_epochs\",\"10\",\"--pretrained_checkpoint\",\"last\",\"--pretrained_s3_bucket\",\"bucket\",\"--pretrained_s3_prefix\",\"rl-sagemaker-pretrained\",\"--s3_bucket\",\"bucket\",\"--s3_prefix\",\"rl-deepracer-sagemaker\",\"--sac_alpha\",\"0.2\",\"--stack_size\",\"1\",\"--term_cond_avg_score\",\"350.0\",\"--term_cond_max_episodes\",\"1000\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_S3_BUCKET=bucket\n",
      "SM_HP_S3_PREFIX=rl-deepracer-sagemaker\n",
      "SM_HP_AWS_REGION=us-east-1\n",
      "SM_HP_MODEL_METADATA_S3_KEY=s3://bucket/custom_files/model_metadata.json\n",
      "SM_HP_RLCOACH_PRESET=deepracer\n",
      "SM_HP_PRETRAINED_S3_BUCKET=bucket\n",
      "SM_HP_PRETRAINED_S3_PREFIX=rl-sagemaker-pretrained\n",
      "SM_HP_PRETRAINED_CHECKPOINT=last\n",
      "SM_HP_BATCH_SIZE=64\n",
      "SM_HP_BETA_ENTROPY=0.01\n",
      "SM_HP_DISCOUNT_FACTOR=0.995\n",
      "SM_HP_E_GREEDY_VALUE=0.05\n",
      "SM_HP_EPSILON_STEPS=10000\n",
      "SM_HP_EXPLORATION_TYPE=categorical\n",
      "SM_HP_LOSS_TYPE=huber\n",
      "SM_HP_LR=0.0003\n",
      "SM_HP_NUM_EPISODES_BETWEEN_TRAINING=20\n",
      "SM_HP_NUM_EPOCHS=10\n",
      "SM_HP_STACK_SIZE=1\n",
      "SM_HP_TERM_COND_AVG_SCORE=350.0\n",
      "SM_HP_TERM_COND_MAX_EPISODES=1000\n",
      "SM_HP_SAC_ALPHA=0.2\n",
      "PYTHONPATH=/usr/local/bin:/opt/amazon:/opt/ml/code:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\n",
      "Invoking script with the following command:\n",
      "\n",
      "/usr/bin/python training_worker.py --RLCOACH_PRESET deepracer --aws_region us-east-1 --batch_size 64 --beta_entropy 0.01 --discount_factor 0.995 --e_greedy_value 0.05 --epsilon_steps 10000 --exploration_type categorical --loss_type huber --lr 0.0003 --model_metadata_s3_key s3://bucket/custom_files/model_metadata.json --num_episodes_between_training 20 --num_epochs 10 --pretrained_checkpoint last --pretrained_s3_bucket bucket --pretrained_s3_prefix rl-sagemaker-pretrained --s3_bucket bucket --s3_prefix rl-deepracer-sagemaker --sac_alpha 0.2 --stack_size 1 --term_cond_avg_score 350.0 --term_cond_max_episodes 1000\n",
      "\n",
      "\n",
      "Using the following hyper-parameters\n",
      "{\n",
      "  \"batch_size\": 64,\n",
      "  \"beta_entropy\": 0.01,\n",
      "  \"discount_factor\": 0.995,\n",
      "  \"e_greedy_value\": 0.05,\n",
      "  \"epsilon_steps\": 10000,\n",
      "  \"exploration_type\": \"categorical\",\n",
      "  \"loss_type\": \"huber\",\n",
      "  \"lr\": 0.0003,\n",
      "  \"num_episodes_between_training\": 20,\n",
      "  \"num_epochs\": 10,\n",
      "  \"stack_size\": 1,\n",
      "  \"term_cond_avg_score\": 350.0,\n",
      "  \"term_cond_max_episodes\": 1000\n",
      "}\n",
      "21:signal-handler (1629601393) Received SIGTERM scheduling shutdown...\n",
      "/usr/local/bin/start.sh: line 24:    22 Terminated              LD_PRELOAD=/libchangehostname.so xvfb-run --auto-servernum -s \"-screen 0 1024x768x16\" train\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please press u to previous or d for next log or x to quit: d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:C 12 Oct 2021 01:37:08.663 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n",
      "21:C 12 Oct 2021 01:37:08.663 # Redis version=6.2.2, bits=64, commit=00000000, modified=0, pid=21, just started\n",
      "21:C 12 Oct 2021 01:37:08.663 # Configuration loaded\n",
      "21:M 12 Oct 2021 01:37:08.663 * monotonic clock: POSIX clock_gettime\n",
      "                _._                                                  \n",
      "           _.-``__ ''-._                                             \n",
      "      _.-``    `.  `_.  ''-._           Redis 6.2.2 (00000000/0) 64 bit\n",
      "  .-`` .-```.  ```\\/    _.,_ ''-._                                  \n",
      " (    '      ,       .-`  | `,    )     Running in standalone mode\n",
      " |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n",
      " |    `-._   `._    /     _.-'    |     PID: 21\n",
      "  `-._    `-._  `-./  _.-'    _.-'                                   \n",
      " |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n",
      " |    `-._`-._        _.-'_.-'    |           https://redis.io       \n",
      "  `-._    `-._`-.__.-'_.-'    _.-'                                   \n",
      " |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n",
      " |    `-._`-._        _.-'_.-'    |                                  \n",
      "  `-._    `-._`-.__.-'_.-'    _.-'                                   \n",
      "      `-._    `-.__.-'    _.-'                                       \n",
      "          `-._        _.-'                                           \n",
      "              `-.__.-'                                               \n",
      "\n",
      "21:M 12 Oct 2021 01:37:08.664 # Server initialized\n",
      "21:M 12 Oct 2021 01:37:08.664 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n",
      "21:M 12 Oct 2021 01:37:08.664 * Ready to accept connections\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2021-10-12 01:37:10,627 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "2021-10-12 01:37:10,826 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\n",
      "Training Env:\n",
      "\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator\": \"RLEstimator\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1-98e0h\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1-98e0h\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"s3_bucket\": \"bucket\",\n",
      "        \"s3_prefix\": \"rl-deepracer-1\",\n",
      "        \"aws_region\": \"us-east-1\",\n",
      "        \"model_metadata_s3_key\": \"s3://bucket/custom_files/model_metadata.json\",\n",
      "        \"RLCOACH_PRESET\": \"deepracer\",\n",
      "        \"pretrained_s3_bucket\": \"bucket\",\n",
      "        \"pretrained_s3_prefix\": \"rl-deepracer-sagemaker\",\n",
      "        \"pretrained_checkpoint\": \"last\",\n",
      "        \"batch_size\": 64,\n",
      "        \"beta_entropy\": 0.01,\n",
      "        \"discount_factor\": 0.995,\n",
      "        \"e_greedy_value\": 0.05,\n",
      "        \"epsilon_steps\": 6000,\n",
      "        \"exploration_type\": \"categorical\",\n",
      "        \"loss_type\": \"huber\",\n",
      "        \"lr\": 3e-05,\n",
      "        \"num_episodes_between_training\": 36,\n",
      "        \"num_epochs\": 10,\n",
      "        \"stack_size\": 1,\n",
      "        \"term_cond_avg_score\": 100000.0,\n",
      "        \"term_cond_max_episodes\": 999999,\n",
      "        \"sac_alpha\": 0.2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rl-deepracer-1\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1-98e0h\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://bucket/rl-deepracer-1/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"training_worker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 12,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1-98e0h\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1-98e0h\"\n",
      "        ]\n",
      "    },\n",
      "    \"user_entry_point\": \"training_worker.py\"\n",
      "}\n",
      "\n",
      "Environment variables:\n",
      "\n",
      "SM_HOSTS=[\"algo-1-98e0h\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"RLCOACH_PRESET\":\"deepracer\",\"aws_region\":\"us-east-1\",\"batch_size\":64,\"beta_entropy\":0.01,\"discount_factor\":0.995,\"e_greedy_value\":0.05,\"epsilon_steps\":6000,\"exploration_type\":\"categorical\",\"loss_type\":\"huber\",\"lr\":3e-05,\"model_metadata_s3_key\":\"s3://bucket/custom_files/model_metadata.json\",\"num_episodes_between_training\":36,\"num_epochs\":10,\"pretrained_checkpoint\":\"last\",\"pretrained_s3_bucket\":\"bucket\",\"pretrained_s3_prefix\":\"rl-deepracer-sagemaker\",\"s3_bucket\":\"bucket\",\"s3_prefix\":\"rl-deepracer-1\",\"sac_alpha\":0.2,\"stack_size\":1,\"term_cond_avg_score\":100000.0,\"term_cond_max_episodes\":999999}\n",
      "SM_USER_ENTRY_POINT=training_worker.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\n",
      "SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-98e0h\",\"hosts\":[\"algo-1-98e0h\"]}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1-98e0h\n",
      "SM_MODULE_NAME=training_worker\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=12\n",
      "SM_NUM_GPUS=1\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://bucket/rl-deepracer-1/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1-98e0h\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-98e0h\"],\"hyperparameters\":{\"RLCOACH_PRESET\":\"deepracer\",\"aws_region\":\"us-east-1\",\"batch_size\":64,\"beta_entropy\":0.01,\"discount_factor\":0.995,\"e_greedy_value\":0.05,\"epsilon_steps\":6000,\"exploration_type\":\"categorical\",\"loss_type\":\"huber\",\"lr\":3e-05,\"model_metadata_s3_key\":\"s3://bucket/custom_files/model_metadata.json\",\"num_episodes_between_training\":36,\"num_epochs\":10,\"pretrained_checkpoint\":\"last\",\"pretrained_s3_bucket\":\"bucket\",\"pretrained_s3_prefix\":\"rl-deepracer-sagemaker\",\"s3_bucket\":\"bucket\",\"s3_prefix\":\"rl-deepracer-1\",\"sac_alpha\":0.2,\"stack_size\":1,\"term_cond_avg_score\":100000.0,\"term_cond_max_episodes\":999999},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rl-deepracer-1\",\"log_level\":20,\"master_hostname\":\"algo-1-98e0h\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://bucket/rl-deepracer-1/source/sourcedir.tar.gz\",\"module_name\":\"training_worker\",\"network_interface_name\":\"eth0\",\"num_cpus\":12,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-98e0h\",\"hosts\":[\"algo-1-98e0h\"]},\"user_entry_point\":\"training_worker.py\"}\n",
      "SM_USER_ARGS=[\"--RLCOACH_PRESET\",\"deepracer\",\"--aws_region\",\"us-east-1\",\"--batch_size\",\"64\",\"--beta_entropy\",\"0.01\",\"--discount_factor\",\"0.995\",\"--e_greedy_value\",\"0.05\",\"--epsilon_steps\",\"6000\",\"--exploration_type\",\"categorical\",\"--loss_type\",\"huber\",\"--lr\",\"3e-05\",\"--model_metadata_s3_key\",\"s3://bucket/custom_files/model_metadata.json\",\"--num_episodes_between_training\",\"36\",\"--num_epochs\",\"10\",\"--pretrained_checkpoint\",\"last\",\"--pretrained_s3_bucket\",\"bucket\",\"--pretrained_s3_prefix\",\"rl-deepracer-sagemaker\",\"--s3_bucket\",\"bucket\",\"--s3_prefix\",\"rl-deepracer-1\",\"--sac_alpha\",\"0.2\",\"--stack_size\",\"1\",\"--term_cond_avg_score\",\"100000.0\",\"--term_cond_max_episodes\",\"999999\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_S3_BUCKET=bucket\n",
      "SM_HP_S3_PREFIX=rl-deepracer-1\n",
      "SM_HP_AWS_REGION=us-east-1\n",
      "SM_HP_MODEL_METADATA_S3_KEY=s3://bucket/custom_files/model_metadata.json\n",
      "SM_HP_RLCOACH_PRESET=deepracer\n",
      "SM_HP_PRETRAINED_S3_BUCKET=bucket\n",
      "SM_HP_PRETRAINED_S3_PREFIX=rl-deepracer-sagemaker\n",
      "SM_HP_PRETRAINED_CHECKPOINT=last\n",
      "SM_HP_BATCH_SIZE=64\n",
      "SM_HP_BETA_ENTROPY=0.01\n",
      "SM_HP_DISCOUNT_FACTOR=0.995\n",
      "SM_HP_E_GREEDY_VALUE=0.05\n",
      "SM_HP_EPSILON_STEPS=6000\n",
      "SM_HP_EXPLORATION_TYPE=categorical\n",
      "SM_HP_LOSS_TYPE=huber\n",
      "SM_HP_LR=3e-05\n",
      "SM_HP_NUM_EPISODES_BETWEEN_TRAINING=36\n",
      "SM_HP_NUM_EPOCHS=10\n",
      "SM_HP_STACK_SIZE=1\n",
      "SM_HP_TERM_COND_AVG_SCORE=100000.0\n",
      "SM_HP_TERM_COND_MAX_EPISODES=999999\n",
      "SM_HP_SAC_ALPHA=0.2\n",
      "PYTHONPATH=/usr/local/bin:/opt/amazon:/opt/ml/code:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\n",
      "Invoking script with the following command:\n",
      "\n",
      "/usr/bin/python training_worker.py --RLCOACH_PRESET deepracer --aws_region us-east-1 --batch_size 64 --beta_entropy 0.01 --discount_factor 0.995 --e_greedy_value 0.05 --epsilon_steps 6000 --exploration_type categorical --loss_type huber --lr 3e-05 --model_metadata_s3_key s3://bucket/custom_files/model_metadata.json --num_episodes_between_training 36 --num_epochs 10 --pretrained_checkpoint last --pretrained_s3_bucket bucket --pretrained_s3_prefix rl-deepracer-sagemaker --s3_bucket bucket --s3_prefix rl-deepracer-1 --sac_alpha 0.2 --stack_size 1 --term_cond_avg_score 100000.0 --term_cond_max_episodes 999999\n",
      "\n",
      "\n",
      "Using the following hyper-parameters\n",
      "{\n",
      "  \"batch_size\": 64,\n",
      "  \"beta_entropy\": 0.01,\n",
      "  \"discount_factor\": 0.995,\n",
      "  \"e_greedy_value\": 0.05,\n",
      "  \"epsilon_steps\": 6000,\n",
      "  \"exploration_type\": \"categorical\",\n",
      "  \"loss_type\": \"huber\",\n",
      "  \"lr\": 3e-05,\n",
      "  \"num_episodes_between_training\": 36,\n",
      "  \"num_epochs\": 10,\n",
      "  \"stack_size\": 1,\n",
      "  \"term_cond_avg_score\": 100000.0,\n",
      "  \"term_cond_max_episodes\": 999999\n",
      "}\n",
      "## Creating graph - name: MultiAgentGraphManager\n",
      "## Start physics before creating graph\n",
      "## Create graph\n",
      "## Creating agent - name: agent\n",
      "[RL] Created agent loggers\n",
      "[RL] Dynamic import of memory:  \"DeepRacerMemoryParameters\" {\n",
      "    \"load_memory_from_file_path\": null,\n",
      "    \"max_size\": [\n",
      "        \"<MemoryGranularity.Transitions: 0>\",\n",
      "        1000000\n",
      "    ],\n",
      "    \"n_step\": -1,\n",
      "    \"shared_memory\": false,\n",
      "    \"train_to_eval_ratio\": 1\n",
      "}\n",
      "\n",
      "[RL] Dynamically imported of memory <markov.memories.deepracer_memory.DeepRacerMemory object at 0x7f383f427518>\n",
      "[RL] Setting devices\n",
      "[RL] Setting filters\n",
      "[RL] Setting filter devices: numpy\n",
      "[RL] Setting Phase\n",
      "[RL] After setting Phase\n",
      "[RL] Setting signals\n",
      "[RL] Agent init successful\n",
      "[RL] ActorCriticAgent init\n",
      "[RL] ActorCriticAgent  init successful\n",
      "## Created agent: agent\n",
      "## Stop physics after creating graph\n",
      "## Creating session\n",
      "Creating regular session\n",
      "21:signal-handler (1634002641) Received SIGTERM scheduling shutdown...\n",
      "/usr/local/bin/start.sh: line 24:    22 Terminated              LD_PRELOAD=/libchangehostname.so xvfb-run --auto-servernum -s \"-screen 0 1024x768x16\" train\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please press u to previous or d for next log or x to quit: x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome!\n"
     ]
    }
   ],
   "source": [
    "view_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aceeba7-f654-4a45-8f72-c966611fba75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd8c75-98f9-4bde-877b-6240cd5b2ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
